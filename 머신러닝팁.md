# 파이프라인 베스트 프랙티스
1. feature 타입 나누기

    수치형(numeric_features)

    범주형(categorical_features)

    → 이렇게 명확히 나누고, 각 타입별로 “Pipeline”을 따로 만듦

2. 수치형 처리 (numeric_transformer)

    SimpleImputer(strategy="mean") : 결측치는 평균으로 대체

    StandardScaler() : 표준화 (평균 0, 표준편차 1)

3. 범주형 처리 (categorical_transformer)

    SimpleImputer(strategy="most_frequent") : 결측치는 최빈값으로 대체

    OneHotEncoder(handle_unknown="ignore") : 새로운 값 들어와도 에러 안 나게 처리

4. ColumnTransformer로 합치기

    수치형에는 numeric_pipeline 적용

    범주형에는 categorical_pipeline 적용

5. Pipeline으로 모델까지 연결

    전처리(preprocessor) + 모델(model)

    LogisticRegression, RandomForest, XGBoost 등 어떤 모델이든 쉽게 교체 가능


## 전처리와 모델을 한번에
```py
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# 수치형 / 범주형 feature 나누기
numeric_features = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']
categorical_features = ['sex', 'island']

# 수치형 파이프라인
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='mean')),
    ('scaler', StandardScaler())
])

# 범주형 파이프라인
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OneHotEncoder(handle_unknown='ignore'))
])

# ColumnTransformer로 합치기
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ]
)

# 최종 파이프라인 (LogisticRegression)
pipe_log = Pipeline([
    ('preprocess', preprocessor),
    ('model', LogisticRegression(max_iter=200))
])

# 최종 파이프라인 (RandomForest)
pipe_rf = Pipeline([
    ('preprocess', preprocessor),
    ('model', RandomForestClassifier(random_state=42))
])

# 교차검증으로 평가
score_log = cross_val_score(pipe_log, X, y, cv=5).mean()
score_rf = cross_val_score(pipe_rf, X, y, cv=5).mean()

print("LogisticRegression 평균 정확도:", score_log)
print("RandomForest 평균 정확도:", score_rf)

```